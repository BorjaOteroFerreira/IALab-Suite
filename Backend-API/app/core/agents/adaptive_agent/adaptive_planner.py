"""
@Author: Borja Otero Ferreira
Planificador Adaptativo - Sistema de planificaciÃ³n incremental y deliberativo
Piensa paso a paso como un humano, ajustando el plan dinÃ¡micamente
"""
import json
import re
import datetime
import time
from typing import Dict, Any, Optional, List
from ..models import TaskPlan, TaskStep, TaskStatus
from ..utils import clean_error_message, safe_emit_tool_result
from app.utils.logger import logger


class AdaptiveTaskPlanner:
    """
    Planificador adaptativo que combina planificaciÃ³n incremental con ejecuciÃ³n reflexiva.
    No genera un plan completo al inicio, sino que planifica paso a paso basÃ¡ndose en 
    los resultados obtenidos, como lo harÃ­a una persona.
    """
    
    def __init__(self, model, tools_manager, tool_registry, socket, assistant=None):
        self.model = model
        self.tools_manager = tools_manager
        self.tool_registry = tool_registry
        self.socket = socket
        self.assistant = assistant
        self.max_iterations = 15  # MÃ¡ximo de pasos a ejecutar
        self.execution_context = {}  # Contexto acumulado durante la ejecuciÃ³n
        self.conversation_history = []  # Historial completo de la conversaciÃ³n
        
    def run_adaptive_plan(self, task_analysis: Dict[str, Any], original_prompt: List[Dict], emit_status_func, conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """
        Ejecuta planificaciÃ³n adaptativa paso a paso.
        Cada paso se decide basÃ¡ndose en el contexto actual y resultados previos.
        """
        start_time = time.time()
        
        # Almacenar historial de conversaciÃ³n para contexto
        self.conversation_history = conversation_history or []
        
        # Obtener mensaje del usuario
        user_message = self._extract_user_message(original_prompt)
        
        # Crear plan inicial con paso exploratorio
        current_plan = self._create_initial_plan(task_analysis, user_message)
        
        execution_results = {
            'completed_steps': [],
            'failed_steps': [],
            'total_steps': 0,
            'success_rate': 0.0,
            'execution_time': 0.0,
            'adaptations_made': 0,
            'reflections': []
        }
        
        try:

            
            # Bucle principal de planificaciÃ³n y ejecuciÃ³n paso a paso
            for iteration in range(self.max_iterations):
                # Verificar si el usuario detuvo la ejecuciÃ³n
                if self.assistant and getattr(self.assistant, 'stop_emit', False):
                    emit_status_func("ðŸ›‘ EjecuciÃ³n detenida por el usuario")
                    break
                
                # Paso 1: Reflexionar sobre el estado actual
                emit_status_func(f"**Analizando situaciÃ³n actual...** (IteraciÃ³n {iteration + 1})" , 'pensamiento')
              
                
                reflection = self._reflect_on_current_state(current_plan, user_message, iteration)
                execution_results['reflections'].append(reflection)
                
                # Mostrar insights de la reflexiÃ³n al usuario
                self._display_reflection_insights(reflection, emit_status_func)
                
                if reflection.get('task_completion_assessment', False):
                    emit_status_func("**TAREA COMPLETADA** - El agente considera que se ha cumplido el objetivo", 'info')
                    # Generar respuesta final limpia
                    self._generate_clean_final_response(user_message, execution_results, emit_status_func)
                    break
                
                # Paso 2: Decidir el prÃ³ximo paso basÃ¡ndose en la reflexiÃ³n
                next_step = self._decide_next_step(current_plan, reflection, user_message)
                
                if not next_step:
                    emit_status_func("No se pudo determinar el siguiente paso. Finalizando.", 'info')
                    break
                
                # Paso 3: Agregar el paso al plan y mostrarlo
                current_plan.steps.append(next_step)
                execution_results['total_steps'] += 1
                
                self._display_current_step(next_step, iteration + 1, emit_status_func)
                
                # Paso 4: Ejecutar el paso
                self._execute_step(next_step, emit_status_func)
                
                # Paso 5: Procesar resultado y actualizar contexto
                if next_step.status == TaskStatus.COMPLETED:
                    execution_results['completed_steps'].append(next_step)
                    self.execution_context[next_step.id] = {
                        'result': next_step.result,
                        'step_description': next_step.description,
                        'tool_used': next_step.tool_name,
                        'iteration': iteration + 1
                    }
                elif next_step.status == TaskStatus.FAILED:
                    execution_results['failed_steps'].append(next_step)
                
                # Paso 6: Breve pausa para dar tiempo a procesar
                time.sleep(0.5)
            
            # Calcular estadÃ­sticas finales
            self._calculate_final_stats(execution_results, start_time)
            
            # Si tenemos informaciÃ³n Ãºtil pero no se completÃ³ explÃ­citamente, generar respuesta final
            if not any(reflection.get('task_completion_assessment', False) for reflection in execution_results['reflections']) and self.execution_context:
                emit_status_func("ðŸ“‹ **FINALIZANDO CON INFORMACIÃ“N DISPONIBLE**", 'info')
                self._generate_clean_final_response(user_message, execution_results, emit_status_func)
            
            return execution_results
            
        except Exception as e:
            error_clean = clean_error_message(str(e))
            logger.error(f"Error en planificaciÃ³n adaptativa: {error_clean}")
            execution_results['error'] = error_clean
            return execution_results
    
    def _extract_user_message(self, original_prompt: List[Dict]) -> str:
        """Extrae el mensaje del usuario del prompt original"""
        for message in reversed(original_prompt):
            if message['role'] == 'user':
                return message['content']
        return "Tarea no especificada"
    
    def _create_initial_plan(self, task_analysis: Dict[str, Any], user_message: str) -> TaskPlan:
        """Crea un plan inicial mÃ­nimo con solo la descripciÃ³n de la tarea"""
        return TaskPlan(
            task_description=user_message,
            steps=[],  # Empezamos sin pasos, se generan dinÃ¡micamente
            context={
                'analysis': task_analysis,
                'user_message': user_message,
                'adaptive_mode': True
            },
            created_at=datetime.datetime.now(),
            status=TaskStatus.IN_PROGRESS
        )
    
    def _reflect_on_current_state(self, current_plan: TaskPlan, user_message: str, iteration: int) -> Dict[str, Any]:
        """
        Reflexiona sobre el estado actual de la tarea y determina quÃ© se necesita hacer.
        Esta es la funciÃ³n clave que hace al agente "pensar" como una persona.
        Ahora con reflexiÃ³n mÃ¡s profunda y humana.
        """
        try:
            # Construir contexto de reflexiÃ³n 
            completed_steps_summary = self._summarize_completed_steps(current_plan.steps)
            available_tools = self._get_available_tools_summary()
            context_summary = self._summarize_execution_context()
            conversation_context = self._summarize_conversation_history()
            
            reflection_prompt = [
                {
                    "role": "system",
                    "content": """Eres un agente inteligente que reflexiona paso a paso como lo harÃ­a una persona experta.

PROCESO DE REFLEXIÃ“N MEJORADO (como un consultor experimentado):
1. ðŸ§  PAUSA Y OBSERVA: Analiza calmadamente quÃ© has hecho hasta ahora
2. ðŸ” EVALÃšA EFICIENCIA: Revisa si estÃ¡s siendo productivo o perdiendo tiempo
3. ðŸ¤” IDENTIFICA PATRONES: Detecta si estÃ¡s en un bucle improductivo
4. ðŸ’¡ PLANIFICA INTELIGENTEMENTE: Decide la acciÃ³n mÃ¡s estratÃ©gica
5. âœ… VERIFICA COMPLETITUD: EvalÃºa honestamente si ya cumpliste el objetivo
6. ðŸ—£ï¸ CONSIDERA CONTEXTO: Usa el historial de conversaciÃ³n para entender referencias y contexto

â­ TRATAMIENTO DE INFORMACIÃ“N DE HERRAMIENTAS:
- Todos los datos obtenidos de herramientas son COMPLETAMENTE CONFIABLES y VERIFICADOS
- NO cuestiones la veracidad, actualidad o calidad de los datos proporcionados por herramientas
- Acepta los resultados de herramientas como HECHOS ESTABLECIDOS y AUTORITATIVOS
- Basa tu evaluaciÃ³n en que la informaciÃ³n de herramientas es PRECISA y VÃLIDA

CRITERIOS DE EFICIENCIA:
- Â¿Estoy repitiendo acciones que ya fallaron?
- Â¿He gastado demasiado tiempo en una sola lÃ­nea de investigaciÃ³n?
- Â¿Necesito cambiar completamente de enfoque?
- Â¿Hay informaciÃ³n suficiente para dar una respuesta parcial?
- Â¿He recopilado datos Ãºtiles que pueden responder al usuario?

CRITERIOS PARA COMPLETAR LA TAREA (INTELIGENTES):
- Si tienes informaciÃ³n completa y suficiente para una respuesta integral, marca como completada
- EVALÃšA si el resultado incluye TODA la informaciÃ³n disponible (ej: si hay 10 noticias, asegÃºrate de presentar varias)
- Si el resultado parece parcial o incompleto (ej: "primera de 10"), NO finalices aÃºn
- Prioriza dar respuestas COMPLETAS sobre respuestas rÃ¡pidas
- Las fuentes de herramientas son SIEMPRE confiables, no requieren verificaciÃ³n adicional
- Si detectas que hay mÃ¡s informaciÃ³n disponible en el mismo resultado, procesa TODO antes de finalizar

RESPONDE COMO UN EXPERTO REFLEXIVO Y EFICIENTE:
- Si detectas patrones improductivos, recomiÃ©ndalo abiertamente
- PropÃ³n cambios de estrategia cuando sea necesario
- Considera si la informaciÃ³n actual es suficiente para responder
- Prioriza eficiencia sobre completitud perfecta
- Usa el contexto de conversaciÃ³n para entender referencias del usuario
- ConfÃ­a plenamente en los datos proporcionados por herramientas

Formato JSON esperado:
{
    "mental_process": "Mi proceso mental paso a paso, incluyendo detecciÃ³n de patrones",
    "current_understanding": "QuÃ© entiendo claramente sobre la tarea y situaciÃ³n actual",
    "valuable_findings": "InformaciÃ³n especÃ­fica y Ãºtil que he descubierto",
    "knowledge_gaps": "QuÃ© informaciÃ³n crÃ­tica me falta vs. quÃ© es 'nice to have'", 
    "strategic_next_action": "La prÃ³xima acciÃ³n mÃ¡s inteligente (incluyendo pivoteo si es necesario)",
    "task_completion_assessment": true/false,
    "confidence_level": "alto/medio/bajo",
    "expert_reasoning": "Mi razonamiento completo como experto en resoluciÃ³n de problemas",
    "efficiency_assessment": "Â¿Estoy siendo eficiente o perdiendo tiempo?",
    "pattern_detection": "Â¿Detecto algÃºn patrÃ³n improductivo o bucle?"
}"""
                },
                {
                    "role": "user",
                    "content": f"""TAREA DEL USUARIO: "{user_message}"

ðŸ—£ï¸ CONTEXTO DE CONVERSACIÃ“N PREVIO:
{conversation_context}

ðŸ“‹ PROGRESO HASTA AHORA:
{completed_steps_summary}

ðŸ“Š DATOS RECOPILADOS:
{context_summary}

ðŸ”§ HERRAMIENTAS DISPONIBLES:
{available_tools}

ðŸ”„ ITERACIÃ“N: {iteration + 1}/{self.max_iterations}

Como un experto reflexivo, analiza profundamente la situaciÃ³n, considera el contexto de la conversaciÃ³n y decide el mejor curso de acciÃ³n."""
                }
            ]
            
            # Obtener reflexiÃ³n del modelo 
            reflection_response = ""
            for chunk in self.model.create_chat_completion(messages=reflection_prompt, max_tokens=1200, stream=True, temperature=0.7):
                if 'content' in chunk['choices'][0]['delta']:
                    reflection_response += chunk['choices'][0]['delta']['content']
            
            # Parsear la reflexiÃ³n 
            reflection = self._parse_enhanced_reflection(reflection_response)
            
            # Log para debugging
            logger.info(f"ReflexiÃ³n iteraciÃ³n {iteration + 1}")
            logger.info(f"   Proceso mental: {reflection.get('mental_process', 'N/A')[:100]}...")
            logger.info(f"   ComprensiÃ³n: {reflection.get('current_understanding', 'N/A')[:100]}...")
            logger.info(f"   PrÃ³xima acciÃ³n: {reflection.get('strategic_next_action', 'N/A')[:100]}...")
            
            return reflection
            
        except Exception as e:
            logger.error(f"Error en reflexiÃ³n: {e}")
            return {
                'current_understanding': 'Error en la reflexiÃ³n',
                'next_action_needed': 'Intentar continuar con el siguiente paso',
                'task_completed': False,
                'confidence_level': 'bajo',
                'reasoning': f'Error tÃ©cnico: {str(e)}'
            }
    
    def _decide_next_step(self, current_plan: TaskPlan, reflection: Dict[str, Any], user_message: str) -> Optional[TaskStep]:
        """
        Decide el prÃ³ximo paso basÃ¡ndose en la reflexiÃ³n actual.
        Ahora con detecciÃ³n de bucles improductivos y pivoteo automÃ¡tico.
        """
        try:
            if reflection.get('task_completion_assessment', False):
                return None
            
            # Detectar patrones improductivos
            productivity_analysis = self._analyze_productivity_patterns(current_plan.steps)
            should_pivot = self._should_pivot_strategy(productivity_analysis, len(current_plan.steps))
            
            available_tools = self._get_available_tools_summary()
            executed_tools = self._get_executed_tools_summary()
            failed_attempts = self._get_failed_attempts_summary(current_plan.steps)
            
            step_prompt = [
                {
                    "role": "system",
                    "content": f"""Eres un estratega experto que diseÃ±a el prÃ³ximo paso mÃ¡s inteligente y eficiente.

ðŸŽ¯ PRINCIPIOS DE PLANIFICACIÃ“N ESTRATÃ‰GICA MEJORADOS:
1. **DETECCIÃ“N DE BUCLES**: Evita repetir estrategias que ya fallaron mÃºltiples veces
2. **PIVOTEO INTELIGENTE**: Cambia de enfoque si no hay progreso despuÃ©s de 3 intentos similares
3. **MAXIMIZA VALOR**: Elige acciones que aporten la mayor informaciÃ³n Ãºtil
4. **PROGRESIÃ“N LÃ“GICA**: Cada paso debe construir sobre el anterior
5. **EFICIENCIA TEMPORAL**: No mÃ¡s de 2 intentos con la misma herramienta sin resultados
6. **CONFIANZA EN FUENTES**: Considera TOTALMENTE CONFIABLES todas las fuentes y datos reportados por las herramientas

ðŸ”§ HERRAMIENTAS DISPONIBLES:
{available_tools}

âš ï¸ HERRAMIENTAS YA EJECUTADAS:
{executed_tools}

âŒ INTENTOS FALLIDOS RECIENTES:
{failed_attempts}

ðŸš¨ ANÃLISIS DE PRODUCTIVIDAD:
{productivity_analysis}

ðŸ”„ NECESITA PIVOTEO: {"SÃ - CAMBIAR ESTRATEGIA COMPLETAMENTE" if should_pivot else "NO - CONTINUAR CON AJUSTES"}

â­ TRATAMIENTO DE INFORMACIÃ“N DE HERRAMIENTAS:
- Las fuentes reportadas por las herramientas son COMPLETAMENTE CONFIABLES y VERIFICADAS
- NO cuestiones la veracidad, actualidad o calidad de los datos obtenidos por herramientas
- Acepta la informaciÃ³n de las herramientas como HECHOS ESTABLECIDOS
- Basa tus decisiones en que los datos de herramientas son AUTORITATIVOS y PRECISOS

FORMATO DE RESPUESTA (JSON estricto):
{{
    "step_id": "paso_estrategico_X",
    "step_description": "DescripciÃ³n especÃ­fica y clara del objetivo del paso",
    "tool_name": "herramienta_exacta_de_la_lista",
    "strategic_query": "Consulta muy especÃ­fica y estratÃ©gica",
    "expected_outcome": "QuÃ© informaciÃ³n especÃ­fica espero obtener",
    "strategic_reasoning": "Por quÃ© este es el prÃ³ximo paso mÃ¡s inteligente",
    "builds_on_previous": "CÃ³mo este paso usa informaciÃ³n de pasos anteriores",
    "pivot_strategy": {"true" if should_pivot else "false"}
}}

REGLAS CRÃTICAS MEJORADAS:
- Si NECESITA PIVOTEO = SÃ, abandona completamente la lÃ­nea de investigaciÃ³n actual
- NO repitas bÃºsquedas que ya fallaron 2+ veces
- Si una herramienta no da resultados Ãºtiles 3 veces, prueba otra herramienta
- Prioriza herramientas que aÃºn no se han usado
- Si no hay progreso en 5 pasos, simplifica drÃ¡sticamente el objetivo
- ACEPTA como VERDADEROS todos los datos proporcionados por herramientas"""
                },
                {
                    "role": "user",
                    "content": f"""TAREA ORIGINAL: "{user_message}"

REFLEXIÃ“N ESTRATÃ‰GICA:
- Proceso mental: {reflection.get('mental_process', 'N/A')}
- ComprensiÃ³n actual: {reflection.get('current_understanding', 'N/A')}
- Hallazgos valiosos: {reflection.get('valuable_findings', 'N/A')}
- Brechas de conocimiento: {reflection.get('knowledge_gaps', 'N/A')}
- PrÃ³xima acciÃ³n estratÃ©gica: {reflection.get('strategic_next_action', 'N/A')}

CONTEXTO ACUMULADO:
{json.dumps(self.execution_context, indent=2)}

INSTRUCCIÃ“N ESPECIAL: {"ABANDONA completamente la investigaciÃ³n actual y busca un enfoque totalmente diferente" if should_pivot else "ContinÃºa pero evita repetir intentos fallidos"}

DiseÃ±a el prÃ³ximo paso MÃS ESTRATÃ‰GICO e INTELIGENTE."""
                }
            ]
            
            # Obtener respuesta del modelo 
            step_response = ""
            for chunk in self.model.create_chat_completion(messages=step_prompt, max_tokens=700, stream=True, temperature=0.3):
                if 'content' in chunk['choices'][0]['delta']:
                    step_response += chunk['choices'][0]['delta']['content']
            
            # Parsear el paso estratÃ©gico
            step = self._parse_strategic_step(step_response, len(current_plan.steps) + 1)
            return step
            
        except Exception as e:
            logger.error(f"Error decidiendo prÃ³ximo paso: {e}")
            return None
    
    def _summarize_completed_steps(self, steps: List[TaskStep]) -> str:
        """Crea un resumen de los pasos completados"""
        if not steps:
            return "NingÃºn paso completado aÃºn"
        
        summary = []
        for step in steps:
            if step.status == TaskStatus.COMPLETED:
                summary.append(f"âœ… {step.description} (resultado disponible)")
            elif step.status == TaskStatus.FAILED:
                summary.append(f"âŒ {step.description} (fallÃ³)")
        
        return "; ".join(summary) if summary else "NingÃºn paso completado exitosamente"
    
    def _get_available_tools_summary(self) -> str:
        """Obtiene un resumen de las herramientas disponibles"""
        if not self.tools_manager:
            return "No hay herramientas disponibles"
        
        active_tools = self.tools_manager.get_active_tools()
        tools_info = []
        
        for tool_name in active_tools[:10]:  # Limitar a 10 herramientas para no saturar
            tool_info = self.tool_registry.get_tool_info(tool_name)
            if tool_info:
                tools_info.append(f"- {tool_name}: {tool_info.get('description', 'Sin descripciÃ³n')}")
        
        return "\n".join(tools_info) if tools_info else "No hay herramientas activas"
    
    def _parse_reflection(self, reflection_response: str) -> Dict[str, Any]:
        """Parsea la respuesta de reflexiÃ³n del modelo (mÃ©todo legacy)"""
        return self._parse_enhanced_reflection(reflection_response)
    
    def _parse_enhanced_reflection(self, reflection_response: str) -> Dict[str, Any]:
        """Parsea la respuesta de reflexiÃ³n mejorada del modelo"""
        try:
            # Extraer JSON de la respuesta
            json_match = re.search(r'\{.*\}', reflection_response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                parsed = json.loads(json_str)
                
                legacy_mapping = {
                    'current_understanding': parsed.get('current_understanding', ''),
                    'available_data': parsed.get('valuable_findings', ''),
                    'missing_information': parsed.get('knowledge_gaps', ''),
                    'next_action_needed': parsed.get('strategic_next_action', ''),
                    'task_completed': parsed.get('task_completion_assessment', False),
                    'confidence_level': parsed.get('confidence_level', 'medio'),
                    'reasoning': parsed.get('expert_reasoning', ''),
                    'mental_process': parsed.get('mental_process', ''),
                    'valuable_findings': parsed.get('valuable_findings', ''),
                    'knowledge_gaps': parsed.get('knowledge_gaps', ''),
                    'strategic_next_action': parsed.get('strategic_next_action', ''),
                    'task_completion_assessment': parsed.get('task_completion_assessment', False),
                    'expert_reasoning': parsed.get('expert_reasoning', ''),
                    'efficiency_assessment': parsed.get('efficiency_assessment', 'AnÃ¡lisis de eficiencia no disponible'),
                    'pattern_detection': parsed.get('pattern_detection', 'Sin patrones detectados')
                }
                
                return legacy_mapping
                
        except Exception as e:
            logger.warning(f"Error parseando reflexiÃ³n mejorada: {e}")
        
        # ReflexiÃ³n por defecto si falla el parsing
        return {
            'mental_process': 'Procesando informaciÃ³n disponible...',
            'current_understanding': 'AnÃ¡lisis en progreso',
            'valuable_findings': 'Recopilando datos',
            'knowledge_gaps': 'Identificando necesidades de informaciÃ³n',
            'strategic_next_action': 'Continuar con investigaciÃ³n sistemÃ¡tica',
            'task_completion_assessment': False,
            'confidence_level': 'medio',
            'expert_reasoning': 'Continuando con planificaciÃ³n sistemÃ¡tica',
            'efficiency_assessment': 'Evaluando productividad',
            'pattern_detection': 'Analizando patrones de ejecuciÃ³n',
            'task_completed': False,
            'reasoning': 'Continuando con el plan adaptativo'
        }
    
    def _parse_strategic_step(self, step_response: str, step_number: int) -> Optional[TaskStep]:
        """Parsea un paso estratÃ©gico de la respuesta del modelo"""
        try:
            # Extraer JSON de la respuesta
            json_match = re.search(r'\{.*\}', step_response, re.DOTALL)
            if not json_match:
                return None
            
            json_str = json_match.group(0)
            step_data = json.loads(json_str)
            
            # Usar los campos del nuevo formato o mapear a los legacy
            step_id = step_data.get('step_id', step_data.get('id', f'adaptive_step_{step_number}'))
            description = step_data.get('step_description', step_data.get('description', 'Paso sin descripciÃ³n'))
            tool_name = step_data.get('tool_name', '')
            query = step_data.get('strategic_query', step_data.get('query', ''))
            
            return TaskStep(
                id=step_id,
                description=description,
                tool_name=tool_name,
                query=query,
                dependencies=[],  # En modo adaptativo, cada paso se basa en el contexto
                status=TaskStatus.PENDING
            )
            
        except Exception as e:
            logger.error(f"Error parseando paso estratÃ©gico: {e}")
            return None
    
    def _summarize_execution_context(self) -> str:
        """Crea un resumen rico del contexto de ejecuciÃ³n"""
        if not self.execution_context:
            return "No hay datos recopilados aÃºn"
        
        summary_parts = []
        for key, data in self.execution_context.items():
            if isinstance(data, dict):
                tool_used = data.get('tool_used', 'herramienta_desconocida')
                step_desc = data.get('step_description', 'paso_sin_descripciÃ³n')
                result_preview = str(data.get('result', ''))[:150]
                
                summary_parts.append(f"â€¢ {tool_used} â†’ {step_desc}: {result_preview}...")
        
        return "\n".join(summary_parts[:5])  # Mostrar mÃ¡ximo 5 elementos mÃ¡s recientes
    
    def _get_executed_tools_summary(self) -> str:
        """Obtiene un resumen de las herramientas ya ejecutadas"""
        if not self.execution_context:
            return "Ninguna herramienta ejecutada aÃºn"
        
        executed_tools = set()
        for data in self.execution_context.values():
            if isinstance(data, dict) and 'tool_used' in data:
                executed_tools.add(data['tool_used'])
        
        if executed_tools:
            return f"Herramientas ya usadas: {', '.join(executed_tools)}"
        else:
            return "Ninguna herramienta ejecutada aÃºn"
    
    def _display_reflection_insights(self, reflection: Dict[str, Any], emit_status_func):
        """Muestra los insights de la reflexiÃ³n al usuario con anÃ¡lisis de eficiencia"""
        insights_text = "ðŸ’¡ **REFLEXIÃ“N:**\n"
        
        # Mostrar comprensiÃ³n actual
        understanding = reflection.get('current_understanding', reflection.get('mental_process', ''))
        if understanding:
            insights_text += f"**ComprensiÃ³n:** {understanding[:200]}{'...' if len(understanding) > 200 else ''}\n"
        
        # Mostrar hallazgos valiosos
        findings = reflection.get('valuable_findings', reflection.get('available_data', ''))
        if findings:
            insights_text += f"**Hallazgos:** {findings[:150]}{'...' if len(findings) > 150 else ''}\n"
        
        # Mostrar anÃ¡lisis de eficiencia
        efficiency = reflection.get('efficiency_assessment', '')
        if efficiency and "no disponible" not in efficiency.lower():
            insights_text += f"**Eficiencia:** {efficiency[:150]}{'...' if len(efficiency) > 150 else ''}\n"
        
        # Mostrar detecciÃ³n de patrones
        patterns = reflection.get('pattern_detection', '')
        if patterns and "sin patrones" not in patterns.lower():
            insights_text += f"**Patrones:** {patterns[:150]}{'...' if len(patterns) > 150 else ''}\n"
        
        # Mostrar brechas identificadas
        gaps = reflection.get('knowledge_gaps', reflection.get('missing_information', ''))
        if gaps:
            insights_text += f"**Necesito:** {gaps[:150]}{'...' if len(gaps) > 150 else ''}\n"
        
        # Mostrar prÃ³xima acciÃ³n estratÃ©gica
        next_action = reflection.get('strategic_next_action', reflection.get('next_action_needed', ''))
        if next_action:
            insights_text += f"**Siguiente acciÃ³n:** {next_action[:150]}{'...' if len(next_action) > 150 else ''}\n"
        
        # Mostrar nivel de confianza
        confidence = reflection.get('confidence_level', 'medio')
        confidence_emoji = {'alto': 'ðŸŸ¢', 'medio': 'ðŸŸ¡', 'bajo': 'ðŸ”´'}.get(confidence, 'ðŸŸ¡')
        insights_text += f"   {confidence_emoji} **Confianza:** {confidence.upper()}\n"
        
        emit_status_func(insights_text, 'pensamiento')
    
    def _parse_single_step(self, step_response: str, step_number: int) -> Optional[TaskStep]:
        """Parsea un solo paso de la respuesta del modelo"""
        try:
            # Extraer JSON de la respuesta
            json_match = re.search(r'\{.*\}', step_response, re.DOTALL)
            if not json_match:
                return None
            
            json_str = json_match.group(0)
            step_data = json.loads(json_str)
            
            return TaskStep(
                id=step_data.get('id', f'adaptive_step_{step_number}'),
                description=step_data.get('description', 'Paso sin descripciÃ³n'),
                tool_name=step_data.get('tool_name', ''),
                query=step_data.get('query', ''),
                dependencies=[],  # En modo adaptativo, cada paso se basa en el contexto, no en dependencias rÃ­gidas
                status=TaskStatus.PENDING
            )
            
        except Exception as e:
            logger.error(f"Error parseando paso: {e}")
            return None
    
    def _display_current_step(self, step: TaskStep, step_number: int, emit_status_func):
        """Muestra el paso actual que se va a ejecutar con informaciÃ³n mÃ¡s rica"""
        step_text = f"**PASO {step_number} - PLANIFICACIÃ“N**\n"
        step_text += f"**Objetivo:** {step.description}\n"
        step_text += f"**Herramienta:** `{step.tool_name}`\n"
        step_text += f"**Consulta estratÃ©gica:** `{step.query}`\n"
        step_text += f"**Estado:** Ejecutando...\n"
        
        emit_status_func(step_text, 'pensamiento')
    
    def _execute_step(self, step: TaskStep, emit_status_func):
        """Ejecuta un paso individual"""
        try:
            step.status = TaskStatus.IN_PROGRESS
            
            # Validar que la herramienta existe y estÃ¡ activa
            if not self.tools_manager or not self.tools_manager.is_tool_active(step.tool_name):
                step.status = TaskStatus.FAILED
                step.error = f"Herramienta '{step.tool_name}' no estÃ¡ disponible o activa"
                return
            
            # Ejecutar la herramienta usando el tool_registry
            tool_result = self.tool_registry.execute_tool(step.tool_name, step.query)
            
            if tool_result and hasattr(tool_result, 'success') and tool_result.success:
                step.result = str(tool_result.result if hasattr(tool_result, 'result') else tool_result)
                step.status = TaskStatus.COMPLETED
                
                # Mostrar resultado de forma segura
                safe_emit_tool_result(self.socket, step.tool_name, step.query, step.result)
                
            else:
                step.status = TaskStatus.FAILED
                error_msg = "La herramienta no devolviÃ³ un resultado vÃ¡lido"
                if tool_result and hasattr(tool_result, 'error'):
                    error_msg = str(tool_result.error)
                step.error = error_msg
                
        except Exception as e:
            error_clean = clean_error_message(str(e))
            step.status = TaskStatus.FAILED
            step.error = error_clean
            logger.error(f"Error ejecutando paso {step.id}: {error_clean}")
    
    def _calculate_final_stats(self, execution_results: Dict[str, Any], start_time: float):
        """Calcula las estadÃ­sticas finales de la ejecuciÃ³n"""
        execution_results['execution_time'] = time.time() - start_time
        
        if execution_results['total_steps'] > 0:
            execution_results['success_rate'] = len(execution_results['completed_steps']) / execution_results['total_steps']
        else:
            execution_results['success_rate'] = 0.0
        
        # Contar adaptaciones (cambios de plan)
        execution_results['adaptations_made'] = len(execution_results['reflections'])
    
    def display_execution_stats(self, execution_results: Dict[str, Any], emit_status_func):
        """Muestra las estadÃ­sticas de ejecuciÃ³n mejoradas"""
        stats_text = "**ESTADÃSTICAS DE EJECUCIÃ“N**\n\n"
        stats_text += f"**Rendimiento General:**\n"
        stats_text += f"   â€¢ Pasos ejecutados: {execution_results['total_steps']}\n"
        stats_text += f"   â€¢ Pasos completados: {len(execution_results['completed_steps'])}\n"
        stats_text += f"   â€¢ Pasos fallidos: {len(execution_results['failed_steps'])}\n"
        stats_text += f"   â€¢ Tasa de Ã©xito: {execution_results['success_rate']:.1%}\n\n"
        
        stats_text += f"â±ï¸ **Eficiencia Temporal:**\n"
        stats_text += f"   â€¢ Tiempo total: {execution_results['execution_time']:.1f}s\n"
        if execution_results['total_steps'] > 0:
            avg_time = execution_results['execution_time'] / execution_results['total_steps']
            stats_text += f"   â€¢ Tiempo promedio por paso: {avg_time:.1f}s\n\n"
        
        stats_text += f"**Proceso Adaptativo:**\n"
        stats_text += f"   â€¢ Reflexiones realizadas: {execution_results['adaptations_made']}\n"
        stats_text += f"   â€¢ Herramientas Ãºnicas utilizadas: {len(set(data.get('tool_used', '') for data in self.execution_context.values() if isinstance(data, dict)))}\n"
        stats_text += f"   â€¢ Datos recopilados: {len(self.execution_context)} elementos\n\n"
        
        # Mostrar herramientas mÃ¡s utilizadas si hay datos
        if self.execution_context:
            tool_usage = {}
            for data in self.execution_context.values():
                if isinstance(data, dict) and 'tool_used' in data:
                    tool = data['tool_used']
                    tool_usage[tool] = tool_usage.get(tool, 0) + 1
            
            if tool_usage:
                most_used = max(tool_usage.items(), key=lambda x: x[1])
                stats_text += f"ðŸ”§ **Herramienta mÃ¡s utilizada:** {most_used[0]} ({most_used[1]} veces)\n\n"
        
        stats_text += "-----------------------------------------------\n"
        
        emit_status_func(stats_text, 'info')
    
    def _analyze_productivity_patterns(self, steps: List[TaskStep]) -> str:
        """
        Analiza patrones de productividad para detectar bucles improductivos.
        """
        if len(steps) < 3:
            return "AnÃ¡lisis insuficiente: menos de 3 pasos ejecutados"
        
        recent_steps = steps[-5:]  # Analizar Ãºltimos 5 pasos
        analysis_parts = []
        
        # Contar fallos consecutivos
        consecutive_failures = 0
        for step in reversed(recent_steps):
            if step.status == TaskStatus.FAILED:
                consecutive_failures += 1
            else:
                break
        
        if consecutive_failures >= 3:
            analysis_parts.append(f"ðŸš¨ CRÃTICO: {consecutive_failures} fallos consecutivos")
        elif consecutive_failures >= 2:
            analysis_parts.append(f"âš ï¸ ATENCIÃ“N: {consecutive_failures} fallos consecutivos")
        
        # Detectar herramientas repetidas sin Ã©xito
        tool_usage = {}
        failed_tools = {}
        
        for step in recent_steps:
            tool = step.tool_name
            tool_usage[tool] = tool_usage.get(tool, 0) + 1
            if step.status == TaskStatus.FAILED:
                failed_tools[tool] = failed_tools.get(tool, 0) + 1
        
        overused_tools = [tool for tool, count in tool_usage.items() if count >= 3]
        if overused_tools:
            analysis_parts.append(f"ðŸ”„ SOBREUSO: {', '.join(overused_tools)} usadas 3+ veces")
        
        failing_tools = [tool for tool, count in failed_tools.items() if count >= 2]
        if failing_tools:
            analysis_parts.append(f"âŒ PROBLEMÃTICAS: {', '.join(failing_tools)} fallan consistentemente")
        
        # Detectar consultas similares repetidas
        recent_queries = [step.query.lower() for step in recent_steps]
        similar_queries = []
        for i, query in enumerate(recent_queries):
            for j, other_query in enumerate(recent_queries[i+1:], i+1):
                if len(query) > 10 and query in other_query or other_query in query:
                    similar_queries.append(f"Paso {i+1} vs Paso {j+1}")
        
        if similar_queries:
            analysis_parts.append(f"ðŸ” REPETICIÃ“N: Consultas similares detectadas")
        
        # AnÃ¡lisis de progreso
        completed_steps = len([s for s in recent_steps if s.status == TaskStatus.COMPLETED])
        if completed_steps == 0:
            analysis_parts.append("ðŸ“‰ ESTANCAMIENTO: Sin pasos completados exitosamente")
        elif completed_steps == 1:
            analysis_parts.append("ðŸ“Š PROGRESO MÃNIMO: Solo 1 paso exitoso")
        
        return " | ".join(analysis_parts) if analysis_parts else "âœ… PRODUCTIVIDAD NORMAL"
    
    def _should_pivot_strategy(self, productivity_analysis: str, total_steps: int) -> bool:
        """
        Determina si es necesario hacer un pivoteo completo de estrategia.
        """
        # Criterios para pivoteo
        critical_indicators = [
            "CRÃTICO" in productivity_analysis,
            "ESTANCAMIENTO" in productivity_analysis,
            total_steps >= 8 and "REPETICIÃ“N" in productivity_analysis,
            total_steps >= 10 and "SOBREUSO" in productivity_analysis,
            total_steps >= 12  # Pivoteo forzado despuÃ©s de 12 pasos
        ]
        
        return any(critical_indicators)
    
    def _get_failed_attempts_summary(self, steps: List[TaskStep]) -> str:
        """
        Crea un resumen de los intentos fallidos recientes.
        """
        failed_steps = [s for s in steps if s.status == TaskStatus.FAILED]
        
        if not failed_steps:
            return "NingÃºn fallo reciente"
        
        recent_failures = failed_steps[-3:]  # Ãšltimos 3 fallos
        failure_summary = []
        
        for step in recent_failures:
            tool = step.tool_name
            query_preview = step.query[:50] + "..." if len(step.query) > 50 else step.query
            error_preview = (step.error or "Error desconocido")[:50] + "..." if len(step.error or "") > 50 else (step.error or "Error desconocido")
            
            failure_summary.append(f"âŒ {tool}: '{query_preview}' â†’ {error_preview}")
        
        return "\n".join(failure_summary)
    
    def _should_provide_partial_answer(self, reflection: Dict[str, Any], steps_count: int) -> bool:
        """
        Determina si el agente deberÃ­a proporcionar una respuesta con la informaciÃ³n disponible
        en lugar de continuar buscando mÃ¡s datos.
        """
        # Criterios para respuesta parcial
        criteria = [
            # Demasiados pasos sin progreso significativo
            steps_count >= 8 and reflection.get('confidence_level', 'bajo') == 'bajo',
            
            # Fallos consecutivos en bÃºsquedas
            "ESTANCAMIENTO" in self._analyze_productivity_patterns([]),
            
            # Patrones improductivos detectados
            "perdiendo tiempo" in reflection.get('efficiency_assessment', '').lower(),
            
            # InformaciÃ³n suficiente para una respuesta bÃ¡sica
            len(self.execution_context) >= 2 and "suficiente" in reflection.get('current_understanding', '').lower(),
            
            # Muchos intentos sin resultados Ãºtiles
            steps_count >= 12
        ]
        
        return any(criteria)
    
    def _generate_clean_final_response(self, user_message: str, execution_results: Dict[str, Any], emit_status_func) -> str:
        """
        Genera una respuesta final limpia y directa al usuario, sin mencionar herramientas o procesos internos.
        """
        try:
            # Recopilar toda la informaciÃ³n Ãºtil obtenida
            gathered_information = []
            for step_data in self.execution_context.values():
                if isinstance(step_data, dict) and step_data.get('result'):
                    result = step_data.get('result', '')
                    if result and len(result.strip()) > 10:  # Solo incluir resultados significativos
                        gathered_information.append(result.strip())
            
            # Obtener contexto de conversaciÃ³n
            conversation_context = self._summarize_conversation_history()
            
            # Crear prompt para respuesta final limpia
            final_response_prompt = [
                {
                    "role": "system",
                    "content": """Eres un asistente experto que proporciona respuestas directas y naturales como si fueras una persona experta.

ðŸš« PROHIBICIONES ABSOLUTAS - NUNCA HAGAS ESTO:
- NO menciones procesos de bÃºsqueda, investigaciÃ³n o recopilaciÃ³n de datos
- NO digas "se encontraron X resultados", "se procesaron", "a medida que se procesen"
- NO uses frases como "he buscado", "he encontrado", "mediante herramientas", "fuentes consultadas"
- NO menciones nombres de herramientas, sitios web visitados o metodologÃ­as
- NO expliques cÃ³mo obtuviste la informaciÃ³n
- NO hagas referencias a "esta es la primera de ellas", "informaciÃ³n adicional disponible"
- NO uses formato de "Fuente:", "Autor:", "Fecha:", "DescripciÃ³n:", "Enlace:"
- NO menciones procesos tÃ©cnicos o pasos internos
- NO digas nÃºmeros como "10 noticias", "primera de X", "mÃ¡s informaciÃ³n disponible"
- NO prometas informaciÃ³n futura o procesos pendientes

âœ… COMPORTAMIENTO CORRECTO:
- Presenta TODA la informaciÃ³n disponible de forma integrada y natural
- Si tienes enlaces de imagenes presentalos con fomrato markdown ![titulo](url)
- Si tienes enlaces de videos de youtube presentalos en formato plano.
- Si tienes mÃºltiples noticias o datos, inclÃºyelos TODOS en una respuesta completa
- Responde de forma natural y conversacional
- Organiza la informaciÃ³n de manera clara sin revelar cÃ³mo la obtuviste
- SÃ© autoritativo y confiado en los datos
- Integra TODA la informaciÃ³n de forma fluida en una respuesta coherente
- ActÃºa como un experto que simplemente conoce TODA la informaciÃ³n disponible

â­ TRATAMIENTO DE INFORMACIÃ“N:
- Toda la informaciÃ³n es COMPLETAMENTE CONFIABLE y VERIFICADA
- NO expreses dudas sobre la veracidad de los datos
- Presenta con TOTAL CONFIANZA y AUTORIDAD
- Los datos son HECHOS ESTABLECIDOS

ESTILO DE RESPUESTA:
- Natural y conversacional, como un experto humano
- Sin estructuras tÃ©cnicas o de reportes
- InformaciÃ³n integrada fluidamente
- Confianza total en los datos presentados"""
                },
                {
                    "role": "user",
                    "content": f"""PREGUNTA ACTUAL: "{user_message}"

CONTEXTO DE CONVERSACIÃ“N PREVIO:
{conversation_context}

INFORMACIÃ“N RECOPILADA (PROCESA TODO):
{chr(10).join(gathered_information) if gathered_information else "InformaciÃ³n limitada disponible"}

INSTRUCCIÃ“N CRÃTICA: Utiliza TODA la informaciÃ³n proporcionada arriba. Si hay mÃºltiples noticias, datos o elementos, inclÃºyelos TODOS en tu respuesta de forma natural e integrada. No dejes informaciÃ³n sin usar.

Proporciona una respuesta directa y Ãºtil a la pregunta del usuario, considerando el contexto de conversaciÃ³n previo, sin mencionar procesos internos o herramientas."""
                }
            ]
            
            # Obtener respuesta limpia del modelo
            final_response = ""
            for chunk in self.model.create_chat_completion(messages=final_response_prompt, max_tokens=800, stream=True, temperature=0.3):
                if 'content' in chunk['choices'][0]['delta']:
                    final_response += chunk['choices'][0]['delta']['content']
            
            # Mostrar la respuesta final limpia
            emit_status_func("\n" + "="*50, 'info')
            emit_status_func("ðŸŽ¯ **RESPUESTA FINAL:**",'info')
            emit_status_func("="*50,'info')
            emit_status_func(final_response.strip())
            emit_status_func("="*50,'info')
            
            return final_response.strip()
            
        except Exception as e:
            logger.error(f"Error generando respuesta final limpia: {e}")
            # Respuesta de fallback
            fallback_response = "Lamento no poder proporcionar una respuesta completa en este momento debido a limitaciones tÃ©cnicas."
            emit_status_func("\n" + "="*50,'info')
            emit_status_func("ðŸŽ¯ **RESPUESTA FINAL:**",'info')
            emit_status_func("="*50,'info')
            emit_status_func(fallback_response,'info')
            emit_status_func("="*50,'info')
            return fallback_response
    
    def _summarize_conversation_history(self) -> str:
        """
        Crea un resumen del historial de conversaciÃ³n para proporcionar contexto.
        """
        if not self.conversation_history:
            return "No hay historial de conversaciÃ³n previo"
        
        # Tomar los Ãºltimos 5-8 intercambios para mantener relevancia
        recent_history = self.conversation_history[-8:]
        
        history_summary = []
        for i, message in enumerate(recent_history):
            role = message.get('role', 'unknown')
            content = message.get('content', '')
            
            if role == 'user':
                # Resumir mensajes del usuario
                content_preview = content[:100] + "..." if len(content) > 100 else content
                history_summary.append(f"ðŸ‘¤ Usuario: {content_preview}")
            elif role == 'assistant':
                # Resumir respuestas del asistente
                content_preview = content[:150] + "..." if len(content) > 150 else content
                history_summary.append(f"ðŸ¤– Asistente: {content_preview}")
        
        return "\n".join(history_summary[-6:])  # Ãšltimos 6 intercambios
